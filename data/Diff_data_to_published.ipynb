{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('J:/'):\n",
    "    rootj = 'J:/'\n",
    "elif os.path.exists('/home/j'):\n",
    "    rootj = '/home/j'\n",
    "else:\n",
    "    raise BaseException('No J Drive access')\n",
    "new_dir = os.path.join('.', 'working') # in the repo\n",
    "old_dir = os.path.join(rootj, 'Project', 'VA')\n",
    "assert os.path.exists(old_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ages = ['Adult', 'Child', 'Neonate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presymptom Data\n",
    "The first step of the process is to process the raw survey data from the intermediate files in the `J:/Project/GC13/Verbal Autopsy/VA Data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Adult\n",
      "Checking Child\n",
      "Checking Neonate\n"
     ]
    }
   ],
   "source": [
    "old_presymp_dir = os.path.join(old_dir, 'Publication_2015', 'Revised Data', 'Presymptom Data')\n",
    "presymp_filename = 'VA Final - {}.dta'\n",
    "for age in ages:\n",
    "    print \"Checking {}\".format(age)\n",
    "    old_df = pd.read_stata(os.path.join(old_presymp_dir, presymp_filename.format(age)), convert_categoricals=False).set_index('sid')\n",
    "    new_df = pd.read_stata(os.path.join(new_dir, presymp_filename.format(age)), convert_categoricals=False).set_index('sid')\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.index).symmetric_difference(new_df.index)) == 0\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.loc[old_df.index].fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Extraction\n",
    "The first step of the process is to use the R `tm` package to create csvs with frequencies of keywords. This analysis exists in the `J:/Project/VA/Publication` directory but not the `J:/Project/VA/Publication_2015` directory.\n",
    "\n",
    "Within the `parse_text.R` file, the variables containing text are hard-coded by module (lines 39 to 53). Open Responses span multiple columns (e.g `a7_*`, `c6_*`). This is because stata, which was used for this analysis, has a limit for the length of string variables. However, the original files have more open reponse variables than are listed in the code (up to 14 instead of up to 10). Some minor truncation occurs between the files generated by the code in the repo and the old versions. To complicate matters, dictionary key words (from DICT-5) are replaces as lower case and at least one observation has a keyword truncated in the middle of the word. Observations should be considered a match if the new version begins with the same text as the old version after converting both to lower case and dropping the last word from the old version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Child_all_words.csv\n",
      "Checking Adult_all_words_pre_dictionary.csv\n",
      "Checking Child_all_words_pre_dictionary.csv\n",
      "Checking Neonate_all_words.csv\n",
      "Checking Neonate_all_words_pre_dictionary.csv\n"
     ]
    }
   ],
   "source": [
    "def mostly_matched(row):\n",
    "    old = row.iloc[0].lower().strip()\n",
    "    new = row.iloc[1].lower().strip()\n",
    "    \n",
    "    # Drop the last word of `old` in case it was truncated in `old`\n",
    "    # and replaced with a keyword in `new`. Split and join `new`\n",
    "    # to remove multiple internal spaces (to match `old`)\n",
    "    old_words = old.split()\n",
    "    old = ' '.join(old_words[:len(old_words) - 1])\n",
    "    return ' '.join(new.split()).startswith(old)\n",
    "\n",
    "old_text_dir = os.path.join(old_dir, 'Publication', 'FreeText', 'Words')\n",
    "for filepath in glob.glob(os.path.join(old_text_dir, '*all_words*.csv')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_csv(filepath)\n",
    "    old_df = old_df[['sid', 'text']].set_index('sid').sort_index()\n",
    "    new_df = pd.read_csv(os.path.join(new_dir, 'freetext', f))\n",
    "    new_df = new_df[['sid', 'text']].set_index('sid').sort_index()\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    fuzzy_match = pd.concat([old_df.text, new_df.text], axis=1).apply(mostly_matched, axis=1)\n",
    "    assert ((old_df.text == new_df.text) | fuzzy_match).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Child_words_all_variables_50freq.csv\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-8ba3d11bd42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'freetext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[1;32massert\u001b[0m \u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymmetric_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "old_text_dir = os.path.join(old_dir, 'Publication', 'FreeText', 'Words')\n",
    "for filepath in glob.glob(os.path.join(old_text_dir, '*50freq.csv')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_csv(filepath)\n",
    "    old_df = old_df.set_index('word_id').sort_index()\n",
    "    new_df = pd.read_csv(os.path.join(new_dir, 'freetext', f))\n",
    "    new_df = new_df.set_index('word_id').sort_index()\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 270)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'word_clock', u'word_ray', u'word_remov'], dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.columns.difference(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'word_alreadi', u'word_also', u'word_alway', u'word_anyth',\n",
       "       u'word_around', u'word_ask', u'word_away', u'word_back', u'word_becam',\n",
       "       u'word_becom', u'word_came', u'word_done', u'word_face', u'word_find',\n",
       "       u'word_first', u'word_gave', u'word_give', u'word_given', u'word_good',\n",
       "       u'word_got', u'word_high', u'word_just', u'word_know', u'word_last',\n",
       "       u'word_later', u'word_like', u'word_mani', u'word_may', u'word_need',\n",
       "       u'word_next', u'word_noth', u'word_old', u'word_one', u'word_place',\n",
       "       u'word_point', u'word_problem', u'word_put', u'word_right',\n",
       "       u'word_said', u'word_saw', u'word_side', u'word_sinc', u'word_small',\n",
       "       u'word_still', u'word_taken', u'word_thought', u'word_three',\n",
       "       u'word_took', u'word_turn', u'word_two', u'word_use', u'word_way',\n",
       "       u'word_well', u'word_went', u'word_whole', u'word_will', u'word_xray',\n",
       "       u'word_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns.difference(old_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_certif       False\n",
       "word_child        False\n",
       "word_colleg       False\n",
       "word_come         False\n",
       "word_day          False\n",
       "word_even         False\n",
       "word_get          False\n",
       "word_medic        False\n",
       "word_month        False\n",
       "word_pneumonia    False\n",
       "word_sever        False\n",
       "word_swell        False\n",
       "word_take         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = old_df.columns.intersection(new_df.columns)\n",
    "matches = (old_df[cols] == new_df.loc[old_df.index, cols]).all()\n",
    "matches.loc[matches != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_pneumonia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-1144</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-1843</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-1854</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-220</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2344</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2555</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2869</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2986</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3037</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3042</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3045</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3737</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D-2001131001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_pneumonia\n",
       "word_id                     \n",
       "B-1144                     1\n",
       "B-1843                     1\n",
       "B-1854                     1\n",
       "B-220                      1\n",
       "B-2344                     1\n",
       "B-2555                     1\n",
       "B-2869                     1\n",
       "B-2986                     2\n",
       "B-3037                     2\n",
       "B-3042                     1\n",
       "B-3045                     2\n",
       "B-3737                     1\n",
       "D-2001131001               1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.loc[old_df.word_pneumonia != new_df.word_pneumonia, ['word_pneumonia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_pneumonia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-1144</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-1843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-1854</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-220</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2344</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2555</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2869</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-2986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3037</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3042</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3045</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-3737</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D-2001131001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_pneumonia\n",
       "word_id                     \n",
       "B-1144                     0\n",
       "B-1843                     0\n",
       "B-1854                     0\n",
       "B-220                      0\n",
       "B-2344                     0\n",
       "B-2555                     0\n",
       "B-2869                     0\n",
       "B-2986                     1\n",
       "B-3037                     1\n",
       "B-3042                     0\n",
       "B-3045                     1\n",
       "B-3737                     0\n",
       "D-2001131001               0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[old_df.word_pneumonia != new_df.word_pneumonia, ['word_pneumonia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_swell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U-1222</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_swell\n",
       "word_id            \n",
       "U-1222            2"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.loc[old_df.word_swell != new_df.word_swell, ['word_swell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_swell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U-1222</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_swell\n",
       "word_id            \n",
       "U-1222            1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[old_df.word_swell != new_df.word_swell, ['word_swell']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Bootstrap\n",
    "The word observations are then bootstrapped to determine significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binarization and Tariff calculation\n",
    "Text is then converted into symptom variables and tariffs are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Child_text.dta\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-065e9950e83e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mold_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[1;32massert\u001b[0m \u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymmetric_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for filepath in glob.glob(os.path.join(old_text_dir, '*.dta')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_stata(filepath)\n",
    "    new_df = pd.read_stata(os.path.join(new_dir, 'freetext', f))\n",
    "    new_df = new_df.set_index('sid').sort_index()\n",
    "    old_df = old_df.set_index('sid').sort_index()\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Master Cause Map.xlsx\n",
      "Checking Master Codebook.xlsx\n"
     ]
    }
   ],
   "source": [
    "old_maps_dir = os.path.join(old_dir, 'Publication_2015', 'Revised Data', 'Code')\n",
    "for filepath in glob.glob(os.path.join(old_maps_dir, '*.xlsx')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_excel(filepath)\n",
    "    new_df = pd.read_excel(os.path.join(new_dir, 'maps', f))\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Neonate_map.dta\n",
      "Checking Child_symptoms.dta\n",
      "Checking Child_map.dta\n",
      "Checking Neonate_symptoms.dta\n",
      "Checking Adult_map_indet.dta\n",
      "Checking Neonate_categories.dta\n",
      "Checking Child_categories.dta\n",
      "Checking Adult_categories.dta\n",
      "Checking Neonate_map_indet.dta\n",
      "Checking Adult_symptoms.dta\n",
      "Checking Adult_map_34.dta\n",
      "Checking Child_map_indet.dta\n",
      "Checking Adult_map.dta\n"
     ]
    }
   ],
   "source": [
    "old_maps_dir = os.path.join(old_dir, 'Publication_2015', 'Revised Data', 'Maps')\n",
    "for filepath in glob.glob(os.path.join(old_maps_dir, '*.dta')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_stata(filepath, convert_categoricals=False)\n",
    "    new_df = pd.read_stata(os.path.join(new_dir, 'maps', f), convert_categoricals=False)\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking neonate_cutoffs.dta\n",
      "Checking child_cutoffs.dta\n",
      "Checking adult_cutoffs.dta\n"
     ]
    }
   ],
   "source": [
    "old_maps_dir = os.path.join(old_dir, 'Publication_2015', 'Revised Data', 'Dump Folder')\n",
    "for filepath in glob.glob(os.path.join(old_maps_dir, '*cutoffs*.dta')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_stata(filepath, convert_categoricals=False)\n",
    "    new_df = pd.read_stata(os.path.join(new_dir, 'dump', f), convert_categoricals=False)\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Child_weightforage.dta\n",
      "Checking Neonate_weightforage.dta\n"
     ]
    }
   ],
   "source": [
    "old_maps_dir = os.path.join(old_dir, 'Publication_2015', 'Revised Data', 'Dump Folder')\n",
    "for filepath in glob.glob(os.path.join(old_maps_dir, '*weightforage*.dta')):\n",
    "    f = filepath.split(os.sep)[-1]\n",
    "    print \"Checking {}\".format(f)\n",
    "    old_df = pd.read_stata(filepath, convert_categoricals=False)\n",
    "    new_df = pd.read_stata(os.path.join(new_dir, 'dump', f), convert_categoricals=False)\n",
    "    if 'sid' in new_df:\n",
    "        new_df = new_df.set_index('sid').sort_index()\n",
    "        old_df = old_df.set_index('sid').sort_index()\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symptom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Adult\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-52f6942e9164>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mold_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_presymp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymp_filename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_categoricals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymp_filename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_categoricals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymmetric_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymmetric_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "old_presymp_dir = os.path.join(old_dir, 'Publication_2015', 'Revised Data', 'Symptom Data')\n",
    "symp_filename = '{}Data.dta'\n",
    "for age in ages:\n",
    "    print \"Checking {}\".format(age)\n",
    "    old_df = pd.read_stata(os.path.join(old_presymp_dir, symp_filename.format(age)), convert_categoricals=False).set_index('sid')\n",
    "    new_df = pd.read_stata(os.path.join(new_dir, symp_filename.format(age)), convert_categoricals=False).set_index('sid')\n",
    "    assert old_df.shape == new_df.shape\n",
    "    assert len(set(old_df.index).symmetric_difference(new_df.index)) == 0\n",
    "    assert len(set(old_df.columns).symmetric_difference(new_df.columns)) == 0\n",
    "    assert (old_df.fillna(0) == new_df.loc[old_df.index].fillna(0)).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
